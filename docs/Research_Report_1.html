<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bias and Variance Tradeoff and BLUE – Seth Kaufman’s Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="site_libs/plotly-binding-4.11.0/plotly.js"></script>

<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>

<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>

<link href="site_libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet">

<script src="site_libs/crosstalk-1.2.2/js/crosstalk.min.js"></script>

<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">

<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Seth Kaufman’s Portfolio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-research-reports" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Research Reports</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-research-reports">    
        <li>
    <a class="dropdown-item" href="./Research_Report_1.html">
 <span class="dropdown-text">Bias &amp; Variance Tradeoff and BLUE</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Research_Report_2.html">
 <span class="dropdown-text">Ensemble Learning Techniques for Fair Classification</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="./Home_Pricing_Competition.html">
 <span class="dropdown-text">Home Pricing Prediction Competition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Applied_Probability_Die_Roll.html">
 <span class="dropdown-text">Conditional Probability Problem</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Electoral_Process.html">
 <span class="dropdown-text">Electoral College Analysis</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bias and Variance Tradeoff and BLUE</h1>
<p class="subtitle lead">Research Report 1: STA 9890</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>Research Report 1 covers the Bias-Variance Trade off in a Linear Data Generating Process (DGP) and the BLUE-ness of Ordinary Least Squares (OLS) Regression. This will include the theoretical background, computation of the gradient descent and weight decay, and bias and variance under both a linear and non-linear DGP. Some basic statistical background is assumed for this report, e.g.: I won’t delve into detail on <span class="math inline">\(Y=f(x)+\epsilon\)</span>, which will be treated as common knowledge.</p>
</section>
<section id="theoretical-background" class="level1">
<h1>2. Theoretical Background</h1>
<section id="bias-and-variance" class="level2">
<h2 class="anchored" data-anchor-id="bias-and-variance">2.1 Bias and Variance</h2>
<p>In modeling, Bias and Variance each play an important role in building a usable model that can predict some outcome <span class="math inline">\(y\)</span>. Both terms combined give us a general error term which in turn can be used to tell us how good a model actually is.</p>
<div class="center-image" style="text-align: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/rr1/bias_variance_tradeoff.png" class="img-fluid figure-img"></p>
<figcaption>Bias and Variance Tradeoff via Wikipedia</figcaption>
</figure>
</div>
</div>
<p>Bias is the “unavoidable model error”, that is it looks at the difference between the ground truth and the predicted values of our model. Variance on the other hand, is the squared difference between the predicted values and the mean of the predicted values.</p>
</section>
<section id="mse" class="level2">
<h2 class="anchored" data-anchor-id="mse">2.2 MSE</h2>
<p>A common error term is the Mean Squared Error or MSE. MSE in the 2D-linear world is defined as:</p>
<p><span class="math inline">\(MSE=\frac{(y-\hat y)^2}{n}\)</span></p>
<p>Or y-true less y-predicted squared over the number of samples n.&nbsp;In the world of Machine Learning though, we usually use matrices to fit our models. For example, in OLS regression, we are searching for a matrix-version of a “line of best fit”, which looks like:</p>
<p><span class="math inline">\(y = X\beta + \epsilon\)</span></p>
<p>In Matrix Notation, the Expected Value breaks out as:</p>
<p><span class="math inline">\(E[MSE]=Bias^2+Variance \space (+Irreducible \space Noise)\)</span></p>
<p>Using the terminology from the previous section:</p>
<p><span class="math inline">\(Bias^2=E[(f(X)-E[\hat f(X)])^2]\)</span></p>
<p>$Variance = E[(f(X)-Ef(X)])^2]</p>
<p>While the Irreducible Noise refers to the fact that, by the nature of how modelling and prediction work, there will simply always be factors that can’t be accounted for. It is denoted by:</p>
<p><span class="math inline">\(\sigma^2=E[\epsilon^2]\)</span></p>
<p>Where <span class="math inline">\(\epsilon\)</span> is the error term.</p>
<p>The full breakdown of the Expected MSE formula is as follows<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span class="math inline">\(MSE(\hat \theta)=E_{\theta}[(\hat \theta - \theta)^2]\)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Breaking this out further:</p>
<p><span class="math inline">\(=E_{\theta}[(\hat \theta - E_\theta[\hat \theta]+E_\theta[\hat \theta]-\theta)^2]\)</span></p>
<p><span class="math inline">\(=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2 + 2(\hat \theta - E_\theta [\hat \theta])(E_\theta [\hat \theta] - \hat \theta)+(E_\theta[\hat \theta - \theta)^2]\)</span></p>
<p><span class="math inline">\(=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2]+E_\theta [2(\hat \theta - E_\theta[\hat \theta])(E_\theta[\hat \theta]-\theta)]+E_\theta[(E_\theta[\hat \theta] - \theta)^2]\)</span></p>
<p><span class="math inline">\(=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2]+2(E_\theta[\hat \theta]-\theta) E_\theta[\hat \theta - E_\theta[\hat \theta]] + (E_\theta[\hat \theta] - \theta)^2\)</span></p>
<p><span class="math inline">\(=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2]+2(E_\theta[\hat \theta]-\theta)E_\theta[\hat \theta - E_\theta[\hat \theta]]+(E_\theta[\hat \theta] - \theta)^2\)</span></p>
<p><span class="math inline">\(=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2]+(E_\theta[\hat \theta] - \theta)^2\)</span></p>
<p>Remembering the Bias and Variance formulas:</p>
<p><span class="math inline">\(Bias^2=E[(f(X)-E[\hat f(X)])^2]=E_\theta[(\hat \theta - E_\theta[\hat \theta])^2]\)</span></p>
<p><span class="math inline">\(Variance=E[(\hat f(X)-E[\hat f(X)])^2]=(E_\theta[\hat \theta] - \theta)^2\)</span></p>
<p>With irreducible error term <span class="math inline">\(E[\epsilon]\)</span></p>
</section>
<section id="ols-regression-and-blue" class="level2">
<h2 class="anchored" data-anchor-id="ols-regression-and-blue">2.3 OLS Regression and BLUE</h2>
<p>OLS Regression is a simple linear model that tries to fit a line to the data that minimizes the Residual Sum of Squares error term. It is generally considered to fit the criteria of BLUE, that is Best Unbiased Linear Estimator. It is the Best because it has the lowest variance among all other linear estimators, it is Linear because that is the model-type, it is Unbiased because there is no difference between the ground truth and the prediction, specifically the expected value of the predicted parameter is equal to the parameter in the DGP, or <span class="math inline">\(E[\hat \theta]=\theta\)</span>, and it is an estimator because it estimates <span class="math inline">\(\theta^2\)</span>. However, there are exceptions to this BLUE property.</p>
</section>
<section id="dgp-and-misspecification" class="level2">
<h2 class="anchored" data-anchor-id="dgp-and-misspecification">2.4 DGP and Misspecification</h2>
<p>A Data Generating Process or DGP is the function of the world that generates data. It is the “ground truth” upon which we try to model the data we do have. Everything discussed until now all is built on-top of this idea that the real-world has unknowns and we can only do our best to try and understand and even predict those unknowns.</p>
<p>In the context of OLS Regression, the faults for OLS stem from the fact that it is only a BLUE model-type when the underlying DGP is linear. However, what happens if the real DGP isn’t <span class="math inline">\(y=X\beta+\epsilon\)</span>, rather it’s <span class="math inline">\(y=X^2 +\epsilon\)</span> a quadratic equation. This would be model misspecification and would cause issues in trying to estimate parameters our DGP. We can test for whether OLS would be a good model type by looking at various factors. First is an expectation of Homoscedasticity in the data, that is <strong><span class="math inline">\(Var(\epsilon_i|X)=\sigma^2\)</span></strong> or that the residuals (that is, <span class="math inline">\(e=y-\hat y\)</span>) have a constant error variance. Running an OLS model on the Credit Card dataset from ISLR<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> with a predicted variable of <span class="math inline">\(y\)</span> being the credit card balance, it produces the following chart:</p>
<div class="center-image" style="text-align: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Research_Report_1_files/figure-html/homoescedasticity-plot_[5]-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"> <em>Homoscedasticity of <span class="math inline">\(\hat y\)</span> from ISL Credit Data Set</em></span></p>
</div>
<p>If these were more evenly spread out around the mean, this would be a good indication that the OLS model would be the best to use. However, that is not the case here: we see somewhat of a checkmark shape that coalesces in the bottom-left.</p>
<p>To check for the unbiased property in the DGP, we can look towards Endogeneity, or that the errors are not affected by the input <span class="math inline">\(X\)</span> variables: <span class="math inline">\(E[\epsilon|X]=0\)</span>. Looking at the input X variables:</p>
<div class="center-image" style="text-align: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Research_Report_1_files/figure-html/endogeneity-plot_[6]-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"> <em>Endogeneity of feature residuals from ISL Credit Data Set</em></span></p>
</div>
<p>The spread is not very even here, though it’s not extremely lopsided. These however show that we likely will have bias in our model if we try to use OLS.</p>
</section>
</section>
<section id="computation" class="level1">
<h1>3. Computation</h1>
<section id="derivation-for-ols" class="level2">
<h2 class="anchored" data-anchor-id="derivation-for-ols">3.1 Derivation for OLS</h2>
<p>OLS seeks to minimize some predictor variable <span class="math inline">\(\hat \beta\)</span> to minimize the error function. To do this, we look at the error term that OLS is trying to minimize, then substitute it in to find a proper value for <span class="math inline">\(\hat \beta\)</span>:</p>
<p><span class="math inline">\(RSS=\Sigma^n_{i=1}=||\epsilon||^2\)</span></p>
<p>Since <span class="math inline">\(y=X\beta+\epsilon\)</span> we can rearrange the terms so <span class="math inline">\(\epsilon=y-X\beta\)</span>, expand the terms, then derive with respect to <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math inline">\(RSS=||y-X||^2=(y-X\beta)^T(y-X\beta)\)</span></p>
<p><span class="math inline">\(\frac{d}{d\beta}[(y-X\beta)^T(y-X\beta)]=\frac{d}{d\beta}[y^Ty-2\beta^T X^Ty+\beta^TX^TX\beta]\)</span></p>
<p>The <span class="math inline">\(y^T y\)</span> term is a constant while <span class="math inline">\(\frac{d}{d\beta}[\beta^T]=1\)</span> so we get the following and set it equal to 0 to minimize it:</p>
<p><span class="math inline">\(-2X^Ty+2X^T X\beta=0\)</span></p>
<p><span class="math inline">\(2X^TX\beta=2X^T y\)</span></p>
<p><span class="math inline">\(\beta = \frac {X^T y} {X^T X}=(X^T X)^{-1} X^T y\)</span></p>
</section>
<section id="ols-gradient" class="level2">
<h2 class="anchored" data-anchor-id="ols-gradient">3.2 OLS Gradient</h2>
<p>Gradient Descent refers to the process of iteratively fitting models to the gradient of a function is the vector field whose value at point <em>p</em> gives the direction and rate of the fastest increase<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. In OLS terms, this translates to:</p>
<p><span class="math inline">\(\beta^{(k+1)}=\beta^{k}-c\nabla\mathcal{L}|_{\beta=\beta^{(k)}}\)</span> where <span class="math inline">\(\nabla\mathcal{L}\)</span> is the loss function on the gradient.</p>
<p>Gradient Descent keeps going until the parameter and objective each converge, or: <span class="math inline">\(\beta^{(k+1)}\approx\beta^{(k)}\)</span> and <span class="math inline">\(\mathcal{L}(\beta^{(k+1)})\approx\mathcal{L}(\beta^{(k)})\)</span>.</p>
<p>The setup is similar to the closed-form derivation from the previous step, it turns into:</p>
<p><span class="math inline">\(\beta^{(k+1)}=\beta^k-c\mathcal{L}|_{\beta=\beta^k}=\beta^k-c(-2X^Ty+2X^TX\beta)=\beta^k-2c(X^TX\beta^k-X^Ty)\)</span></p>
<p>Plotting it out, it looks like:</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Converged at iteration 293</code></pre>
</div>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-cf63773417a5f3d493ca" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-cf63773417a5f3d493ca">{"x":{"data":[{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293],"y":[5.6468833328362589,3.3809280496059144,2.3073716995837215,1.7935622039474499,1.5426966313750901,1.4155262302626075,1.3467145829324605,1.3055994833115587,1.2777855135047207,1.2565087294218882,1.2385856438941918,1.2225127983416497,1.2075752201450842,1.1934281694593178,1.1799009162484677,1.1669046766698787,1.1543894131454215,1.1423235577762096,1.1306844899393469,1.1194540592502777,1.1086164757552159,1.0981573109732212,1.0880630203824007,1.0783207108367614,1.0689180231847053,1.059843069220149,1.0510843944012536,1.04263095292657,1.0344720888681924,1.0265975203971727,1.0189973257016165,1.0116619299324148,1.0045820928564677,0.99774889705932801,0.99115373661550676,0.98478830618074809,0.97864459047775287,0.97271485415513947,0.96699163200356175,0.9614677195150777,0.9561361637730994,0.95099025466105658,0.94602351637848148,0.94122969925370037,0.93660277184273055,0.93213691330435688,0.92782650604173289,0.9236661286011778,0.91965054881918196,0.91577471720893799,0.91203376057802721,0.90842297586917797,0.90493782421629665,0.90157392520824819,0.8983270513531203,0.89519312273596441,0.89216820186324908,0.88924848868749884,0.88643031580581833,0.88371014382622515,0.88108455689592247,0.87855025838585299,0.87610406672606833,0.87374291138664373,0.87146382899904928,0.8692639596130679,0.8671405430845216,0.86509091558923257,0.86311250625880975,0.86120283393399677,0.85935950403147643,0.8575802055201639,0.85586270800316167,0.85420485890168207,0.85260458073737433,0.8510598685096149,0.84956878716444373,0.84812946915194076,0.84674011206895283,0.84539897638418726,0.8441043832427918,0.84285471234764597,0.84164839991467799,0.84048393669962373,0.83935986609372859,0.8382747822859824,0.8372273284895636,0.83621619523024693,0.83524011869460879,0.834297879135942,0.83338829933585978,0.83251024311964761,0.83166261392347807,0.83084435341168228,0.83005444014232377,0.82929188827938893,0.82855574634996476,0.82784509604483092,0.82715905106094922,0.8264967559843861,0.82585738521225627,0.82524014191232076,0.82464425701892763,0.82406898826402175,0.82351361924200051,0.82297745850723003,0.82245983870308481,0.82196011572140415,0.82147766789130616,0.82101189519633166,0.82056221851892941,0.82012807891132533,0.81970893689185587,0.81930427176587306,0.81891358097036726,0.81853637944147317,0.81817219900406268,0.81782058778265465,0.81748110963289156,0.81715334359286984,0.81683688335362625,0.81653133674811318,0.8162363252580167,0.8159514835377929,0.81567645895532159,0.8154109111485971,0.8151545115978962,0.81490694321288004,0.81466789993411237,0.81443708634848666,0.81421421731807853,0.81399901762195315,0.81379122161047635,0.81359057287169134,0.81339682390934098,0.8132097358321263,0.81302907805381264,0.81285462800380059,0.81268617084779882,0.81252349921824463,0.8123664129541327,0.81221471884992191,0.81206823041320486,0.81192676763083427,0.8117901567432072,0.81165823002642767,0.81153082558206868,0.81140778713426898,0.81128896383390914,0.81117421006962021,0.81106338528538335,0.81095635380449482,0.81085298465966982,0.81075315142907378,0.81065673207807254,0.81056360880650147,0.81047366790126329,0.81038679959406512,0.81030289792411714,0.81022186060562051,0.81014358889987514,0.81006798749184772,0.80999496437104401,0.80992443071653331,0.80985630078598436,0.80979049180856699,0.80972692388158984,0.80966551987073998,0.80960620531380101,0.80954890832772719,0.80949355951895618,0.80944009189684796,0.80938844079014172,0.80933854376632219,0.80929034055379834,0.80924377296679229,0.8091987848328458,0.809155321922854,0.80911333188353507,0.80907276417225371,0.80903356999411513,0.8089957022412505,0.80895911543421706,0.808923765665439,0.80888961054461994,0.80885660914605451,0.80882472195777622,0.80879391083247576,0.808764138940128,0.80873537072226964,0.80870757184786735,0.80868070917072332,0.80865475068836312,0.80862966550235549,0.80860542378001177,0.80858199671741982,0.80855935650376431,0.80853747628688766,0.80851633014004998,0.80849589302984659,0.80847614078523999,0.80845705006767032,0.80843859834220533,0.80842076384969375,0.80840352557988771,0.80838686324549958,0.80837075725716001,0.80835518869924949,0.80834013930656656,0.80832559144181115,0.80831152807384721,0.80829793275672279,0.80828478960941974,0.80827208329630529,0.80825979900826539,0.80824792244449128,0.80823643979490134,0.80822533772317062,0.80821460335035278,0.80820422423907001,0.80819418837825074,0.80818448416839905,0.80817510040737495,0.80816602627666811,0.80815725132814897,0.80814876547127901,0.80814055896076442,0.80813262238463979,0.80812494665276513,0.80811752298571959,0.80811034290408401,0.80810339821809252,0.80809668101764498,0.80809018366266405,0.80808389877378861,0.80807781922338739,0.80807193812688727,0.80806624883439881,0.80806074492263513,0.80805542018710863,0.80805026863459861,0.80804528447588109,0.80804046211870861,0.8080357961610346,0.80803128138447167,0.80802691274797656,0.80802268538175404,0.80801859458137137,0.80801463580207666,0.8080108046533141,0.80800709689342831,0.80800350842455315,0.80800003528767494,0.80799667365787009,0.80799341983970308,0.80799027026278736,0.80798722147749702,0.80798427015082852,0.80798141306240401,0.80797864710061384,0.80797596925889092,0.8079733766321161,0.80797086641314431,0.80796843588945466,0.80796608243991219,0.80796380353164421,0.80796159671702306,0.807959459630754,0.80795738998706146,0.80795538557697555,0.80795344426570836,0.80795156399012447,0.80794974275629505,0.80794797863713974,0.80794626977014661,0.8079446143551724,0.80794301065231833,0.80794145697987874,0.80793995171236066,0.80793849327857059,0.80793708015976839,0.80793571088788374,0.80793438404379481,0.80793309825566451,0.80793185219733565,0.80793064458678066,0.80792947418460404,0.80792833979259659,0.80792724025233942,0.80792617444385584,0.8079251412843097,0.80792413972674715,0.80792316875888326],"text":["Iteration:   1<br />Loss: 5.6468833","Iteration:   2<br />Loss: 3.3809280","Iteration:   3<br />Loss: 2.3073717","Iteration:   4<br />Loss: 1.7935622","Iteration:   5<br />Loss: 1.5426966","Iteration:   6<br />Loss: 1.4155262","Iteration:   7<br />Loss: 1.3467146","Iteration:   8<br />Loss: 1.3055995","Iteration:   9<br />Loss: 1.2777855","Iteration:  10<br />Loss: 1.2565087","Iteration:  11<br />Loss: 1.2385856","Iteration:  12<br />Loss: 1.2225128","Iteration:  13<br />Loss: 1.2075752","Iteration:  14<br />Loss: 1.1934282","Iteration:  15<br />Loss: 1.1799009","Iteration:  16<br />Loss: 1.1669047","Iteration:  17<br />Loss: 1.1543894","Iteration:  18<br />Loss: 1.1423236","Iteration:  19<br />Loss: 1.1306845","Iteration:  20<br />Loss: 1.1194541","Iteration:  21<br />Loss: 1.1086165","Iteration:  22<br />Loss: 1.0981573","Iteration:  23<br />Loss: 1.0880630","Iteration:  24<br />Loss: 1.0783207","Iteration:  25<br />Loss: 1.0689180","Iteration:  26<br />Loss: 1.0598431","Iteration:  27<br />Loss: 1.0510844","Iteration:  28<br />Loss: 1.0426310","Iteration:  29<br />Loss: 1.0344721","Iteration:  30<br />Loss: 1.0265975","Iteration:  31<br />Loss: 1.0189973","Iteration:  32<br />Loss: 1.0116619","Iteration:  33<br />Loss: 1.0045821","Iteration:  34<br />Loss: 0.9977489","Iteration:  35<br />Loss: 0.9911537","Iteration:  36<br />Loss: 0.9847883","Iteration:  37<br />Loss: 0.9786446","Iteration:  38<br />Loss: 0.9727149","Iteration:  39<br />Loss: 0.9669916","Iteration:  40<br />Loss: 0.9614677","Iteration:  41<br />Loss: 0.9561362","Iteration:  42<br />Loss: 0.9509903","Iteration:  43<br />Loss: 0.9460235","Iteration:  44<br />Loss: 0.9412297","Iteration:  45<br />Loss: 0.9366028","Iteration:  46<br />Loss: 0.9321369","Iteration:  47<br />Loss: 0.9278265","Iteration:  48<br />Loss: 0.9236661","Iteration:  49<br />Loss: 0.9196505","Iteration:  50<br />Loss: 0.9157747","Iteration:  51<br />Loss: 0.9120338","Iteration:  52<br />Loss: 0.9084230","Iteration:  53<br />Loss: 0.9049378","Iteration:  54<br />Loss: 0.9015739","Iteration:  55<br />Loss: 0.8983271","Iteration:  56<br />Loss: 0.8951931","Iteration:  57<br />Loss: 0.8921682","Iteration:  58<br />Loss: 0.8892485","Iteration:  59<br />Loss: 0.8864303","Iteration:  60<br />Loss: 0.8837101","Iteration:  61<br />Loss: 0.8810846","Iteration:  62<br />Loss: 0.8785503","Iteration:  63<br />Loss: 0.8761041","Iteration:  64<br />Loss: 0.8737429","Iteration:  65<br />Loss: 0.8714638","Iteration:  66<br />Loss: 0.8692640","Iteration:  67<br />Loss: 0.8671405","Iteration:  68<br />Loss: 0.8650909","Iteration:  69<br />Loss: 0.8631125","Iteration:  70<br />Loss: 0.8612028","Iteration:  71<br />Loss: 0.8593595","Iteration:  72<br />Loss: 0.8575802","Iteration:  73<br />Loss: 0.8558627","Iteration:  74<br />Loss: 0.8542049","Iteration:  75<br />Loss: 0.8526046","Iteration:  76<br />Loss: 0.8510599","Iteration:  77<br />Loss: 0.8495688","Iteration:  78<br />Loss: 0.8481295","Iteration:  79<br />Loss: 0.8467401","Iteration:  80<br />Loss: 0.8453990","Iteration:  81<br />Loss: 0.8441044","Iteration:  82<br />Loss: 0.8428547","Iteration:  83<br />Loss: 0.8416484","Iteration:  84<br />Loss: 0.8404839","Iteration:  85<br />Loss: 0.8393599","Iteration:  86<br />Loss: 0.8382748","Iteration:  87<br />Loss: 0.8372273","Iteration:  88<br />Loss: 0.8362162","Iteration:  89<br />Loss: 0.8352401","Iteration:  90<br />Loss: 0.8342979","Iteration:  91<br />Loss: 0.8333883","Iteration:  92<br />Loss: 0.8325102","Iteration:  93<br />Loss: 0.8316626","Iteration:  94<br />Loss: 0.8308444","Iteration:  95<br />Loss: 0.8300544","Iteration:  96<br />Loss: 0.8292919","Iteration:  97<br />Loss: 0.8285557","Iteration:  98<br />Loss: 0.8278451","Iteration:  99<br />Loss: 0.8271591","Iteration: 100<br />Loss: 0.8264968","Iteration: 101<br />Loss: 0.8258574","Iteration: 102<br />Loss: 0.8252401","Iteration: 103<br />Loss: 0.8246443","Iteration: 104<br />Loss: 0.8240690","Iteration: 105<br />Loss: 0.8235136","Iteration: 106<br />Loss: 0.8229775","Iteration: 107<br />Loss: 0.8224598","Iteration: 108<br />Loss: 0.8219601","Iteration: 109<br />Loss: 0.8214777","Iteration: 110<br />Loss: 0.8210119","Iteration: 111<br />Loss: 0.8205622","Iteration: 112<br />Loss: 0.8201281","Iteration: 113<br />Loss: 0.8197089","Iteration: 114<br />Loss: 0.8193043","Iteration: 115<br />Loss: 0.8189136","Iteration: 116<br />Loss: 0.8185364","Iteration: 117<br />Loss: 0.8181722","Iteration: 118<br />Loss: 0.8178206","Iteration: 119<br />Loss: 0.8174811","Iteration: 120<br />Loss: 0.8171533","Iteration: 121<br />Loss: 0.8168369","Iteration: 122<br />Loss: 0.8165313","Iteration: 123<br />Loss: 0.8162363","Iteration: 124<br />Loss: 0.8159515","Iteration: 125<br />Loss: 0.8156765","Iteration: 126<br />Loss: 0.8154109","Iteration: 127<br />Loss: 0.8151545","Iteration: 128<br />Loss: 0.8149069","Iteration: 129<br />Loss: 0.8146679","Iteration: 130<br />Loss: 0.8144371","Iteration: 131<br />Loss: 0.8142142","Iteration: 132<br />Loss: 0.8139990","Iteration: 133<br />Loss: 0.8137912","Iteration: 134<br />Loss: 0.8135906","Iteration: 135<br />Loss: 0.8133968","Iteration: 136<br />Loss: 0.8132097","Iteration: 137<br />Loss: 0.8130291","Iteration: 138<br />Loss: 0.8128546","Iteration: 139<br />Loss: 0.8126862","Iteration: 140<br />Loss: 0.8125235","Iteration: 141<br />Loss: 0.8123664","Iteration: 142<br />Loss: 0.8122147","Iteration: 143<br />Loss: 0.8120682","Iteration: 144<br />Loss: 0.8119268","Iteration: 145<br />Loss: 0.8117902","Iteration: 146<br />Loss: 0.8116582","Iteration: 147<br />Loss: 0.8115308","Iteration: 148<br />Loss: 0.8114078","Iteration: 149<br />Loss: 0.8112890","Iteration: 150<br />Loss: 0.8111742","Iteration: 151<br />Loss: 0.8110634","Iteration: 152<br />Loss: 0.8109564","Iteration: 153<br />Loss: 0.8108530","Iteration: 154<br />Loss: 0.8107532","Iteration: 155<br />Loss: 0.8106567","Iteration: 156<br />Loss: 0.8105636","Iteration: 157<br />Loss: 0.8104737","Iteration: 158<br />Loss: 0.8103868","Iteration: 159<br />Loss: 0.8103029","Iteration: 160<br />Loss: 0.8102219","Iteration: 161<br />Loss: 0.8101436","Iteration: 162<br />Loss: 0.8100680","Iteration: 163<br />Loss: 0.8099950","Iteration: 164<br />Loss: 0.8099244","Iteration: 165<br />Loss: 0.8098563","Iteration: 166<br />Loss: 0.8097905","Iteration: 167<br />Loss: 0.8097269","Iteration: 168<br />Loss: 0.8096655","Iteration: 169<br />Loss: 0.8096062","Iteration: 170<br />Loss: 0.8095489","Iteration: 171<br />Loss: 0.8094936","Iteration: 172<br />Loss: 0.8094401","Iteration: 173<br />Loss: 0.8093884","Iteration: 174<br />Loss: 0.8093385","Iteration: 175<br />Loss: 0.8092903","Iteration: 176<br />Loss: 0.8092438","Iteration: 177<br />Loss: 0.8091988","Iteration: 178<br />Loss: 0.8091553","Iteration: 179<br />Loss: 0.8091133","Iteration: 180<br />Loss: 0.8090728","Iteration: 181<br />Loss: 0.8090336","Iteration: 182<br />Loss: 0.8089957","Iteration: 183<br />Loss: 0.8089591","Iteration: 184<br />Loss: 0.8089238","Iteration: 185<br />Loss: 0.8088896","Iteration: 186<br />Loss: 0.8088566","Iteration: 187<br />Loss: 0.8088247","Iteration: 188<br />Loss: 0.8087939","Iteration: 189<br />Loss: 0.8087641","Iteration: 190<br />Loss: 0.8087354","Iteration: 191<br />Loss: 0.8087076","Iteration: 192<br />Loss: 0.8086807","Iteration: 193<br />Loss: 0.8086548","Iteration: 194<br />Loss: 0.8086297","Iteration: 195<br />Loss: 0.8086054","Iteration: 196<br />Loss: 0.8085820","Iteration: 197<br />Loss: 0.8085594","Iteration: 198<br />Loss: 0.8085375","Iteration: 199<br />Loss: 0.8085163","Iteration: 200<br />Loss: 0.8084959","Iteration: 201<br />Loss: 0.8084761","Iteration: 202<br />Loss: 0.8084571","Iteration: 203<br />Loss: 0.8084386","Iteration: 204<br />Loss: 0.8084208","Iteration: 205<br />Loss: 0.8084035","Iteration: 206<br />Loss: 0.8083869","Iteration: 207<br />Loss: 0.8083708","Iteration: 208<br />Loss: 0.8083552","Iteration: 209<br />Loss: 0.8083401","Iteration: 210<br />Loss: 0.8083256","Iteration: 211<br />Loss: 0.8083115","Iteration: 212<br />Loss: 0.8082979","Iteration: 213<br />Loss: 0.8082848","Iteration: 214<br />Loss: 0.8082721","Iteration: 215<br />Loss: 0.8082598","Iteration: 216<br />Loss: 0.8082479","Iteration: 217<br />Loss: 0.8082364","Iteration: 218<br />Loss: 0.8082253","Iteration: 219<br />Loss: 0.8082146","Iteration: 220<br />Loss: 0.8082042","Iteration: 221<br />Loss: 0.8081942","Iteration: 222<br />Loss: 0.8081845","Iteration: 223<br />Loss: 0.8081751","Iteration: 224<br />Loss: 0.8081660","Iteration: 225<br />Loss: 0.8081573","Iteration: 226<br />Loss: 0.8081488","Iteration: 227<br />Loss: 0.8081406","Iteration: 228<br />Loss: 0.8081326","Iteration: 229<br />Loss: 0.8081249","Iteration: 230<br />Loss: 0.8081175","Iteration: 231<br />Loss: 0.8081103","Iteration: 232<br />Loss: 0.8081034","Iteration: 233<br />Loss: 0.8080967","Iteration: 234<br />Loss: 0.8080902","Iteration: 235<br />Loss: 0.8080839","Iteration: 236<br />Loss: 0.8080778","Iteration: 237<br />Loss: 0.8080719","Iteration: 238<br />Loss: 0.8080662","Iteration: 239<br />Loss: 0.8080607","Iteration: 240<br />Loss: 0.8080554","Iteration: 241<br />Loss: 0.8080503","Iteration: 242<br />Loss: 0.8080453","Iteration: 243<br />Loss: 0.8080405","Iteration: 244<br />Loss: 0.8080358","Iteration: 245<br />Loss: 0.8080313","Iteration: 246<br />Loss: 0.8080269","Iteration: 247<br />Loss: 0.8080227","Iteration: 248<br />Loss: 0.8080186","Iteration: 249<br />Loss: 0.8080146","Iteration: 250<br />Loss: 0.8080108","Iteration: 251<br />Loss: 0.8080071","Iteration: 252<br />Loss: 0.8080035","Iteration: 253<br />Loss: 0.8080000","Iteration: 254<br />Loss: 0.8079967","Iteration: 255<br />Loss: 0.8079934","Iteration: 256<br />Loss: 0.8079903","Iteration: 257<br />Loss: 0.8079872","Iteration: 258<br />Loss: 0.8079843","Iteration: 259<br />Loss: 0.8079814","Iteration: 260<br />Loss: 0.8079786","Iteration: 261<br />Loss: 0.8079760","Iteration: 262<br />Loss: 0.8079734","Iteration: 263<br />Loss: 0.8079709","Iteration: 264<br />Loss: 0.8079684","Iteration: 265<br />Loss: 0.8079661","Iteration: 266<br />Loss: 0.8079638","Iteration: 267<br />Loss: 0.8079616","Iteration: 268<br />Loss: 0.8079595","Iteration: 269<br />Loss: 0.8079574","Iteration: 270<br />Loss: 0.8079554","Iteration: 271<br />Loss: 0.8079534","Iteration: 272<br />Loss: 0.8079516","Iteration: 273<br />Loss: 0.8079497","Iteration: 274<br />Loss: 0.8079480","Iteration: 275<br />Loss: 0.8079463","Iteration: 276<br />Loss: 0.8079446","Iteration: 277<br />Loss: 0.8079430","Iteration: 278<br />Loss: 0.8079415","Iteration: 279<br />Loss: 0.8079400","Iteration: 280<br />Loss: 0.8079385","Iteration: 281<br />Loss: 0.8079371","Iteration: 282<br />Loss: 0.8079357","Iteration: 283<br />Loss: 0.8079344","Iteration: 284<br />Loss: 0.8079331","Iteration: 285<br />Loss: 0.8079319","Iteration: 286<br />Loss: 0.8079306","Iteration: 287<br />Loss: 0.8079295","Iteration: 288<br />Loss: 0.8079283","Iteration: 289<br />Loss: 0.8079272","Iteration: 290<br />Loss: 0.8079262","Iteration: 291<br />Loss: 0.8079251","Iteration: 292<br />Loss: 0.8079241","Iteration: 293<br />Loss: 0.8079232"],"type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(0,100,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[293,278],"y":[0.80792316875888326,0.8579231687588833],"text":"Iteration: 293<br />Loss: 0.8079232<br />Iteration - 15: 278<br />Loss + 0.05: 0.8579232","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(0,0,139,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[293],"y":[0.80792316875888326],"text":"Iteration: 293<br />Loss: 0.8079232","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,139,1)","opacity":1,"size":11.338582677165356,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(0,0,139,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[278],"y":[1.2579231687588832],"text":"Converged at:<br />Iteration 293","hovertext":"Iteration - 15: 278<br />Loss + 0.45: 1.257923<br />paste0(\"Converged at:\\nIteration \", Iteration): Converged at:<br />Iteration 293","textfont":{"size":15.118110236220474,"color":"rgba(0,0,139,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[3,8],"y":[2.3073716995837215,2.3573716995837213],"text":"Iteration: 3<br />Loss: 2.307372<br />Iteration + 5: 8<br />Loss + 0.05: 2.357372","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(255,140,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[3],"y":[2.3073716995837215],"text":"Iteration: 3<br />Loss: 2.307372","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(255,140,0,1)","opacity":1,"size":11.338582677165356,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(255,140,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[53],"y":[2.3573716995837213],"text":"Natural Stopping Point:<br />Iteration 3","hovertext":"Iteration + 50: 53<br />Loss + 0.05: 2.357372<br />paste0(\"Natural Stopping Point:\\nIteration \", Iteration): Natural Stopping Point:<br />Iteration 3","textfont":{"size":15.118110236220474,"color":"rgba(255,140,0,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":45.356579493565803,"r":8.6342880863428828,"b":44.034869240348698,"l":37.127438771274399},"plot_bgcolor":"rgba(229,229,229,1)","paper_bgcolor":"rgba(242,242,242,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762},"title":{"text":"Gradient Descent Convergence for OLS","font":{"color":"rgba(0,0,0,1)","family":"","size":20.722291407222919},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-13.600000000000001,307.60000000000002],"tickmode":"array","ticktext":["0","100","200","300"],"tickvals":[0,100,200,300],"categoryorder":"array","categoryarray":["0","100","200","300"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":4.3171440431714405,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":13.814860938148611},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(179,179,179,1)","gridwidth":0,"zeroline":false,"anchor":"y","title":{"text":"Iterations","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.56597516055501451,5.8888313410401274],"tickmode":"array","ticktext":["1","2","3","4","5"],"tickvals":[1,2,3,4,5],"categoryorder":"array","categoryarray":["1","2","3","4","5"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":4.3171440431714414,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":13.814860938148611},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(179,179,179,1)","gridwidth":0,"zeroline":false,"anchor":"x","title":{"text":"Loss (MSE)","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(102,102,102,1)","width":0,"linetype":"solid"},"yref":"paper","xref":"paper","layer":"below","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":13.814860938148611}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"460815f04082":{"x":{},"y":{},"type":"scatter"},"46089573429":{"x":{},"y":{},"xend":{},"yend":{}},"460846f42b3c":{"x":{},"y":{}},"4608651cd3f":{"x":{},"y":{},"label":{}},"460835bf32f8":{"x":{},"y":{},"xend":{},"yend":{}},"4608ad239a6":{"x":{},"y":{}},"46085b3338e3":{"x":{},"y":{},"label":{}}},"cur_data":"460815f04082","visdat":{"460815f04082":["function (y) ","x"],"46089573429":["function (y) ","x"],"460846f42b3c":["function (y) ","x"],"4608651cd3f":["function (y) ","x"],"460835bf32f8":["function (y) ","x"],"4608ad239a6":["function (y) ","x"],"46085b3338e3":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"> <em>Sample Gradient Descent with convergence in OLS</em></span></p>
</div>
</section>
<section id="ols-weight-decay" class="level2">
<h2 class="anchored" data-anchor-id="ols-weight-decay">3.3 OLS Weight Decay</h2>
<p>To try and make up for the issues of overfitting and large parameterization, OLS can implement a process known as weight decay. This adds a penalty term to the gradient formula to penalize large parameters and try to keep the model simple. The set-up is similar to before but with an added penalty term:</p>
<p><span class="math inline">\(\beta^{(k+1)}=\beta^{k}-c\nabla\mathcal{L}|_{\beta=\beta^{(k)}}-\mathcal{w}\beta^{(k)}\)</span></p>
<p>Plugging this into the gradient derivative from the previous section, we get to this step:</p>
<p><span class="math inline">\(=\frac{\partial}{\partial \beta}[y^Ty-2\beta^TX^Ty+\beta^TX^TX\beta-\mathcal{w}\beta]\)</span></p>
<p>The <span class="math inline">\(y^Ty\)</span> term disappears since it’s a constant in this context and the <span class="math inline">\(\beta^T\)</span> terms set to <span class="math inline">\(\frac{\partial}{\partial \beta}[\beta^T]=1\)</span></p>
<p><span class="math inline">\(\nabla\mathcal{L}=-2X^Ty+2X^TX\beta-\mathcal{w}\beta\)</span></p>
<p>Plugging this back into the original formula for <span class="math inline">\(\beta^{(k+1)}\)</span>:</p>
<p><span class="math inline">\(\beta^{(k+1)}=\beta^{(k)}-c(-2X^Ty+2X^TX\beta-2\mathcal{w}\beta)\)</span></p>
<p>Which finally equals:</p>
<p><span class="math inline">\(\beta^{(k+1)}=\beta^{(k)}-2c(X^TX\beta^{(k)}-X^Ty-\mathcal{w}I)\)</span></p>
<p>And in simulation-land, we can see this will converge sooner than just regular Gradient Descent from the previous section:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Simulate Gradient Descent</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Function</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>gradient_descent_weight_decay <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">alpha =</span> <span class="fl">0.01</span>, <span class="at">lambda_val =</span> <span class="fl">0.1</span>, <span class="at">num_iterations =</span> <span class="dv">1000</span>, <span class="at">tol =</span> <span class="fl">1e-6</span>) {</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add intercept column if not already present</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="fu">all</span>(X[,<span class="dv">1</span>] <span class="sc">==</span> <span class="dv">1</span>)) {</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, X)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, k)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  loss_history <span class="ot">&lt;-</span> <span class="fu">numeric</span>()</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_iterations) {</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute gradient with weight decay</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    gradient <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="fu">t</span>(X) <span class="sc">%*%</span> X <span class="sc">%*%</span> beta <span class="sc">-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y <span class="sc">+</span> lambda_val <span class="sc">*</span> beta) <span class="sc">/</span> n</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    beta <span class="ot">&lt;-</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> alpha <span class="sc">*</span> lambda_val) <span class="sc">*</span> beta <span class="sc">-</span> alpha <span class="sc">*</span> gradient</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute loss (MSE + L2 penalty)</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">&lt;-</span> <span class="fu">mean</span>((y <span class="sc">-</span> X <span class="sc">%*%</span> beta)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> lambda_val <span class="sc">*</span> <span class="fu">sum</span>(beta<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    loss_history[i] <span class="ot">&lt;-</span> loss</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convergence check</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">&amp;&amp;</span> <span class="fu">abs</span>(loss_history[i] <span class="sc">-</span> loss_history[i <span class="sc">-</span> <span class="dv">1</span>]) <span class="sc">&lt;</span> tol) {</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">message</span>(<span class="st">"Converged at iteration "</span>, i)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">beta =</span> beta, <span class="at">loss_history =</span> loss_history)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Converged at iteration 141</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-f9e07acd5b205c232c5f" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-f9e07acd5b205c232c5f">{"x":{"data":[{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141],"y":[5.7039020594532497,3.5938044827728435,2.6511576776570358,2.2252495597512221,2.0284480163095262,1.9335734871947723,1.88435985226921,1.8558864006548017,1.8370913386405059,1.8230431527295794,1.8115241975549625,1.801520104568155,1.7925515830533065,1.7843786358410409,1.7768694639871496,1.7699422333823609,1.7635391007645622,1.7576145397207332,1.7521300184165831,1.7470515083770297,1.7423482627307163,1.7379921697973026,1.7339573724192017,1.7302200141707536,1.7267580495771115,1.7235510894383546,1.7205802676245565,1.717828122638335,1.7152784904336276,1.7129164064835285,1.7107280158235123,1.7087004901725118,1.706821951440864,1.7050814010575521,1.7034686546300284,1.7019742815076748,1.7005895488644005,1.699306369951985,1.6981172562063038,1.6970152729151435,1.695993998179796,1.695047484923754,1.6941702257209168,1.6933571202331452,1.6926034450629404,1.6919048258416631,1.6912572113871915,1.6906568497773353,1.6901002661967954,1.6895842424260545,1.6891057978503778,1.6886621718761559,1.6882508076502125,1.6878693369854314,1.6875155664032573,1.6871874642102416,1.6868831485319644,1.6866008762333515,1.6863390326596608,1.6860961221373065,1.6858707591781854,1.6856616603353554,1.6854676366617884,1.6852875867274881,1.6851204901535994,1.6849654016251769,1.6848214453471542,1.6846878099106553,1.6845637435392504,1.6844485496869961,1.6843415829621984,1.6842422453527599,1.6841499827307742,1.684064281615675,1.6839846661767885,1.6839106954575571,1.6838419608050128,1.6837780834893024,1.6837187124991846,1.6836635225004752,1.6836122119453676,1.6835645013214613,1.6835201315301567,1.6834788623848347,1.6834404712199584,1.6834047516028872,1.6833715121407975,1.6833405753756785,1.683311776760879,1.6832849637131788,1.6832599947347913,1.6832367386001286,1.683215073602538,1.6831948868565747,1.6831760736517032,1.6831585368536288,1.6831421863497333,1.6831269385353571,1.6831127158379124,1.6830994462760254,1.6830870630511245,1.6830755041690781,1.6830647120896578,1.6830546334017766,1.6830452185225975,1.6830364214187532,1.6830281993480369,1.6830205126200648,1.6830133243745018,1.6830066003755597,1.6830003088215633,1.6829944201684828,1.6829889069663881,1.6829837437078896,1.6829789066876679,1.6829743738722858,1.6829701247795192,1.682966140366509,1.6829624029260843,1.682958895990657,1.6829556042431246,1.6829525134342798,1.682949610306228,1.6829468825213927,1.6829443185966833,1.6829419078424526,1.6829396403058925,1.6829375067185377,1.6829354984475833,1.6829336074507295,1.6829318262343005,1.6829301478143948,1.6829285656808444,1.68292707376378,1.6829256664026104,1.6829243383172376,1.6829230845813488,1.6829219005976261,1.682920782074746,1.6829197250060237,1.6829187256495923],"text":["Iteration:   1<br />Loss: 5.703902","Iteration:   2<br />Loss: 3.593804","Iteration:   3<br />Loss: 2.651158","Iteration:   4<br />Loss: 2.225250","Iteration:   5<br />Loss: 2.028448","Iteration:   6<br />Loss: 1.933573","Iteration:   7<br />Loss: 1.884360","Iteration:   8<br />Loss: 1.855886","Iteration:   9<br />Loss: 1.837091","Iteration:  10<br />Loss: 1.823043","Iteration:  11<br />Loss: 1.811524","Iteration:  12<br />Loss: 1.801520","Iteration:  13<br />Loss: 1.792552","Iteration:  14<br />Loss: 1.784379","Iteration:  15<br />Loss: 1.776869","Iteration:  16<br />Loss: 1.769942","Iteration:  17<br />Loss: 1.763539","Iteration:  18<br />Loss: 1.757615","Iteration:  19<br />Loss: 1.752130","Iteration:  20<br />Loss: 1.747052","Iteration:  21<br />Loss: 1.742348","Iteration:  22<br />Loss: 1.737992","Iteration:  23<br />Loss: 1.733957","Iteration:  24<br />Loss: 1.730220","Iteration:  25<br />Loss: 1.726758","Iteration:  26<br />Loss: 1.723551","Iteration:  27<br />Loss: 1.720580","Iteration:  28<br />Loss: 1.717828","Iteration:  29<br />Loss: 1.715278","Iteration:  30<br />Loss: 1.712916","Iteration:  31<br />Loss: 1.710728","Iteration:  32<br />Loss: 1.708700","Iteration:  33<br />Loss: 1.706822","Iteration:  34<br />Loss: 1.705081","Iteration:  35<br />Loss: 1.703469","Iteration:  36<br />Loss: 1.701974","Iteration:  37<br />Loss: 1.700590","Iteration:  38<br />Loss: 1.699306","Iteration:  39<br />Loss: 1.698117","Iteration:  40<br />Loss: 1.697015","Iteration:  41<br />Loss: 1.695994","Iteration:  42<br />Loss: 1.695047","Iteration:  43<br />Loss: 1.694170","Iteration:  44<br />Loss: 1.693357","Iteration:  45<br />Loss: 1.692603","Iteration:  46<br />Loss: 1.691905","Iteration:  47<br />Loss: 1.691257","Iteration:  48<br />Loss: 1.690657","Iteration:  49<br />Loss: 1.690100","Iteration:  50<br />Loss: 1.689584","Iteration:  51<br />Loss: 1.689106","Iteration:  52<br />Loss: 1.688662","Iteration:  53<br />Loss: 1.688251","Iteration:  54<br />Loss: 1.687869","Iteration:  55<br />Loss: 1.687516","Iteration:  56<br />Loss: 1.687187","Iteration:  57<br />Loss: 1.686883","Iteration:  58<br />Loss: 1.686601","Iteration:  59<br />Loss: 1.686339","Iteration:  60<br />Loss: 1.686096","Iteration:  61<br />Loss: 1.685871","Iteration:  62<br />Loss: 1.685662","Iteration:  63<br />Loss: 1.685468","Iteration:  64<br />Loss: 1.685288","Iteration:  65<br />Loss: 1.685120","Iteration:  66<br />Loss: 1.684965","Iteration:  67<br />Loss: 1.684821","Iteration:  68<br />Loss: 1.684688","Iteration:  69<br />Loss: 1.684564","Iteration:  70<br />Loss: 1.684449","Iteration:  71<br />Loss: 1.684342","Iteration:  72<br />Loss: 1.684242","Iteration:  73<br />Loss: 1.684150","Iteration:  74<br />Loss: 1.684064","Iteration:  75<br />Loss: 1.683985","Iteration:  76<br />Loss: 1.683911","Iteration:  77<br />Loss: 1.683842","Iteration:  78<br />Loss: 1.683778","Iteration:  79<br />Loss: 1.683719","Iteration:  80<br />Loss: 1.683664","Iteration:  81<br />Loss: 1.683612","Iteration:  82<br />Loss: 1.683565","Iteration:  83<br />Loss: 1.683520","Iteration:  84<br />Loss: 1.683479","Iteration:  85<br />Loss: 1.683440","Iteration:  86<br />Loss: 1.683405","Iteration:  87<br />Loss: 1.683372","Iteration:  88<br />Loss: 1.683341","Iteration:  89<br />Loss: 1.683312","Iteration:  90<br />Loss: 1.683285","Iteration:  91<br />Loss: 1.683260","Iteration:  92<br />Loss: 1.683237","Iteration:  93<br />Loss: 1.683215","Iteration:  94<br />Loss: 1.683195","Iteration:  95<br />Loss: 1.683176","Iteration:  96<br />Loss: 1.683159","Iteration:  97<br />Loss: 1.683142","Iteration:  98<br />Loss: 1.683127","Iteration:  99<br />Loss: 1.683113","Iteration: 100<br />Loss: 1.683099","Iteration: 101<br />Loss: 1.683087","Iteration: 102<br />Loss: 1.683076","Iteration: 103<br />Loss: 1.683065","Iteration: 104<br />Loss: 1.683055","Iteration: 105<br />Loss: 1.683045","Iteration: 106<br />Loss: 1.683036","Iteration: 107<br />Loss: 1.683028","Iteration: 108<br />Loss: 1.683021","Iteration: 109<br />Loss: 1.683013","Iteration: 110<br />Loss: 1.683007","Iteration: 111<br />Loss: 1.683000","Iteration: 112<br />Loss: 1.682994","Iteration: 113<br />Loss: 1.682989","Iteration: 114<br />Loss: 1.682984","Iteration: 115<br />Loss: 1.682979","Iteration: 116<br />Loss: 1.682974","Iteration: 117<br />Loss: 1.682970","Iteration: 118<br />Loss: 1.682966","Iteration: 119<br />Loss: 1.682962","Iteration: 120<br />Loss: 1.682959","Iteration: 121<br />Loss: 1.682956","Iteration: 122<br />Loss: 1.682953","Iteration: 123<br />Loss: 1.682950","Iteration: 124<br />Loss: 1.682947","Iteration: 125<br />Loss: 1.682944","Iteration: 126<br />Loss: 1.682942","Iteration: 127<br />Loss: 1.682940","Iteration: 128<br />Loss: 1.682938","Iteration: 129<br />Loss: 1.682935","Iteration: 130<br />Loss: 1.682934","Iteration: 131<br />Loss: 1.682932","Iteration: 132<br />Loss: 1.682930","Iteration: 133<br />Loss: 1.682929","Iteration: 134<br />Loss: 1.682927","Iteration: 135<br />Loss: 1.682926","Iteration: 136<br />Loss: 1.682924","Iteration: 137<br />Loss: 1.682923","Iteration: 138<br />Loss: 1.682922","Iteration: 139<br />Loss: 1.682921","Iteration: 140<br />Loss: 1.682920","Iteration: 141<br />Loss: 1.682919"],"type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(0,100,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[141,140],"y":[1.6829187256495923,1.9329187256495923],"text":"Iteration: 141<br />Loss: 1.682919<br />label_x: 140<br />label_y: 1.932919","type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(0,0,139,1)","dash":"-"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[141],"y":[1.6829187256495923],"text":"Iteration: 141<br />Loss: 1.682919","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,139,1)","opacity":1,"size":11.338582677165356,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(0,0,139,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[130],"y":[2.2829187256495924],"text":"Converged at:<br />Iteration 141","hovertext":"label_x - 10: 130<br />label_y + 0.35: 2.282919<br />paste0(\"Converged at:\\nIteration \", Iteration): Converged at:<br />Iteration 141","textfont":{"size":15.118110236220474,"color":"rgba(0,0,139,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[3,18],"y":[2.6511576776570358,2.6511576776570358],"text":"Iteration: 3<br />Loss: 2.651158<br />label_x: 18<br />label_y: 2.651158","type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(255,140,0,1)","dash":"-"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[3],"y":[2.6511576776570358],"text":"Iteration: 3<br />Loss: 2.651158","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(255,140,0,1)","opacity":1,"size":11.338582677165356,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(255,140,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[23],"y":[3.0511576776570357],"text":"Natural Stopping Point:<br />Iteration 3","hovertext":"label_x + 5: 23<br />label_y + 0.4: 3.051158<br />paste0(\"Natural Stopping Point:\\nIteration \", Iteration): Natural Stopping Point:<br />Iteration 3","textfont":{"size":15.118110236220474,"color":"rgba(255,140,0,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":45.356579493565803,"r":8.6342880863428828,"b":44.034869240348698,"l":37.127438771274399},"plot_bgcolor":"rgba(229,229,229,1)","paper_bgcolor":"rgba(242,242,242,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762},"title":{"text":"Gradient Descent Convergence with Weight Decay","font":{"color":"rgba(0,0,0,1)","family":"","size":20.722291407222919},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-6,148],"tickmode":"array","ticktext":["0","50","100"],"tickvals":[0,50,100],"categoryorder":"array","categoryarray":["0","50","100"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":4.3171440431714405,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":13.814860938148611},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(179,179,179,1)","gridwidth":0,"zeroline":false,"anchor":"y","title":{"text":"Iterations","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[1.4818695589594095,5.9049512261434325],"tickmode":"array","ticktext":["2","3","4","5"],"tickvals":[2,3,4,5],"categoryorder":"array","categoryarray":["2","3","4","5"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":4.3171440431714414,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":13.814860938148611},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(179,179,179,1)","gridwidth":0,"zeroline":false,"anchor":"x","title":{"text":"Loss (MSE + L2 Penalty)","font":{"color":"rgba(0,0,0,1)","family":"","size":17.268576172685762}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(102,102,102,1)","width":0,"linetype":"solid"},"yref":"paper","xref":"paper","layer":"below","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":13.814860938148611}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"460848a92c84":{"x":{},"y":{},"type":"scatter"},"4608277067a1":{"x":{},"y":{},"xend":{},"yend":{}},"460866e071a0":{"x":{},"y":{}},"460820192fee":{"x":{},"y":{},"label":{}},"460858631a19":{"x":{},"y":{},"xend":{},"yend":{}},"46081aeb2108":{"x":{},"y":{}},"460825a3ea":{"x":{},"y":{},"label":{}}},"cur_data":"460848a92c84","visdat":{"460848a92c84":["function (y) ","x"],"4608277067a1":["function (y) ","x"],"460866e071a0":["function (y) ","x"],"460820192fee":["function (y) ","x"],"460858631a19":["function (y) ","x"],"46081aeb2108":["function (y) ","x"],"460825a3ea":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"><em>Sample Weight Decay and Gradient Descent with convergence in OLS</em></span></p>
</div>
</section>
<section id="ridge-regression" class="level2">
<h2 class="anchored" data-anchor-id="ridge-regression">3.4 Ridge Regression</h2>
<p>Ridge Regression is an <span class="math inline">\(\ell_p-Regression\)</span> function, specifically <span class="math inline">\(\ell_2\)</span>. It applies a penalty term to the original OLS parameters, <span class="math inline">\(\lambda\)</span>, to minimize the effects of large coefficients and overfitting.</p>
<p><span class="math inline">\(\ell_2 (\beta) = ||y-X\beta||^2+\lambda ||\beta||^2\)</span></p>
<p>Breaking this out then deriving it with respect to β:</p>
<p><span class="math inline">\(\ell_2 (\beta) = (y-X\beta)^T (y-X\beta) + \lambda \beta^T \beta = -2X^T y + 2X^T X + 2\lambda \beta\)</span></p>
<p>Setting this equal to 0 and solving for <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math inline">\(-2X^Ty + 2X^T X \beta + 2 \lambda \beta = 0\)</span></p>
<p>Where <span class="math inline">\(\beta = (X^T X \lambda I)^{-1} X^T y\)</span></p>
<p>Deriving the gradient term <span class="math inline">\(\beta^{k+1} = \beta^k - c \nabla L|_{\beta = \beta^k}=\beta^k-2c(X^T y + X^T X \beta^k - \lambda I)\)</span></p>
<p>Which is the same form as OLS with weight decay: <span class="math inline">\(\beta^k - 2c(X^T y + X^T X \beta^k - wI)\)</span></p>
</section>
</section>
<section id="bias-and-variance-under-a-linear-dgp" class="level1">
<h1>4. Bias and Variance under a Linear DGP</h1>
<section id="positing-a-linear-dgp-with-monte-carlo" class="level2">
<h2 class="anchored" data-anchor-id="positing-a-linear-dgp-with-monte-carlo">4.1 Positing a Linear DGP with Monte Carlo</h2>
<p>If we assume a Linear DGP of <span class="math inline">\(y=X\beta + \epsilon\)</span>, we can use Monte Carlo simulations to view bias and variance under these conditions.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">2</span>)  <span class="co"># Intercept and slope</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize storage</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Monte Carlo loop</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  beta_estimates <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> num_simulations, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  in_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  out_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (sim <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_simulations) {</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate training data</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> beta_true[<span class="dv">1</span>] <span class="sc">+</span> beta_true[<span class="dv">2</span>] <span class="sc">*</span> X <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    X_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, X)  <span class="co"># Add intercept</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit model</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    beta_hat <span class="ot">&lt;-</span> <span class="fu">coef</span>(model)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    beta_estimates[sim, ] <span class="ot">&lt;-</span> beta_hat</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># In-sample MSE</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(model)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    in_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate test set</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    X_test <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    y_test <span class="ot">&lt;-</span> beta_true[<span class="dv">1</span>] <span class="sc">+</span> beta_true[<span class="dv">2</span>] <span class="sc">*</span> X_test <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    test_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">X =</span> X_test)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Out-of-sample MSE</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> test_df)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    out_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> y_test_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute bias and variance for β1 (slope)</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>  beta1_hat <span class="ot">&lt;-</span> beta_estimates[, <span class="dv">2</span>]</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>  bias_beta1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(beta1_hat) <span class="sc">-</span> beta_true[<span class="dv">2</span>]</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>  variance_beta1 <span class="ot">&lt;-</span> <span class="fu">var</span>(beta1_hat)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store results</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(results, <span class="fu">data.frame</span>(</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> n,</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_beta1 =</span> bias_beta1,</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">variance_beta1 =</span> variance_beta1,</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">in_sample_mse =</span> <span class="fu">mean</span>(in_sample_mse),</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">out_sample_mse =</span> <span class="fu">mean</span>(out_sample_mse)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Bias, Variance, and MSEs</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Bias</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> bias_beta1)) <span class="sc">+</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bias of β1 vs. Sample Size"</span>, <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Bias"</span>)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Variance</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> variance_beta1)) <span class="sc">+</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Variance of β1 vs. Sample Size"</span>, <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Variance"</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a><span class="co"># In-Sample MSE</span></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> in_sample_mse)) <span class="sc">+</span></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"In-Sample MSE vs. Sample Size"</span>, <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Out-of-Sample MSE</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> out_sample_mse)) <span class="sc">+</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Out-of-Sample MSE vs. Sample Size"</span>, <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Arrange in 2x2 grid</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Research_Report_1_files/figure-html/linear-dgp-monte-carlo_[10]-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"><em>Bias and Variance under a Linear DGP with Monte Carlo simulations</em></span></p>
</div>
</section>
<section id="repeating-with-ridge-regression" class="level2">
<h2 class="anchored" data-anchor-id="repeating-with-ridge-regression">4.2 Repeating with Ridge Regression</h2>
<p>Let’s repeat the Monte Carlo simulations using Ridge Regression to see the difference between it and OLS</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set simulation parameters</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>lambda_ridge <span class="ot">&lt;-</span> <span class="fl">1.0</span>  <span class="co"># L2 regularization strength</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Storage for results</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ridge_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over sample sizes</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  beta_estimates <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> num_simulations, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  in_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  out_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (sim <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_simulations) {</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate training data</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> beta_true[<span class="dv">1</span>] <span class="sc">+</span> beta_true[<span class="dv">2</span>] <span class="sc">*</span> X <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    X_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, X)  <span class="co"># Add intercept column</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit Ridge regression (glmnet expects matrix input, no intercept term)</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    ridge_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X_mat, <span class="at">y =</span> y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> lambda_ridge, <span class="at">intercept =</span> <span class="cn">FALSE</span>, <span class="at">standardize =</span> <span class="cn">FALSE</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    beta_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(<span class="fu">coef</span>(ridge_model, <span class="at">s =</span> lambda_ridge))[<span class="sc">-</span><span class="dv">1</span>]  <span class="co"># drop intercept row</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    beta_estimates[sim, ] <span class="ot">&lt;-</span> beta_hat</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># In-sample prediction</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="ot">&lt;-</span> X_mat <span class="sc">%*%</span> beta_hat</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    in_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Test set</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    X_test <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    y_test <span class="ot">&lt;-</span> beta_true[<span class="dv">1</span>] <span class="sc">+</span> beta_true[<span class="dv">2</span>] <span class="sc">*</span> X_test <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    X_test_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, X_test)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Out-of-sample prediction</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="ot">&lt;-</span> X_test_mat <span class="sc">%*%</span> beta_hat</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    out_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> y_test_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Bias and variance of β1 (slope)</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>  beta1_hat <span class="ot">&lt;-</span> beta_estimates[, <span class="dv">2</span>]</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>  bias_beta1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(beta1_hat) <span class="sc">-</span> beta_true[<span class="dv">2</span>]</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>  variance_beta1 <span class="ot">&lt;-</span> <span class="fu">var</span>(beta1_hat)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Save results</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>  ridge_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ridge_results, <span class="fu">data.frame</span>(</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> n,</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_beta1 =</span> bias_beta1,</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">variance_beta1 =</span> variance_beta1,</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">in_sample_mse =</span> <span class="fu">mean</span>(in_sample_mse),</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">out_sample_mse =</span> <span class="fu">mean</span>(out_sample_mse)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Bias</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> bias_beta1)) <span class="sc">+</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bias of β1 vs. Sample Size (Ridge)"</span>,</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Bias"</span>)</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> variance_beta1)) <span class="sc">+</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Variance of β1 vs. Sample Size (Ridge)"</span>,</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Variance"</span>)</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a><span class="co"># In-sample MSE</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> in_sample_mse)) <span class="sc">+</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"In-Sample MSE vs. Sample Size (Ridge)"</span>,</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Out-of-sample MSE</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> out_sample_mse)) <span class="sc">+</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Out-of-Sample MSE vs. Sample Size (Ridge)"</span>,</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Display all four plots in 2x2 layout</span></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Research_Report_1_files/figure-html/linear-dgp-monte-carlo-ridge_[11]-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"> <em>Bias and Variance under a Linear DGP with Monte Carlo simulations using Ridge Regression</em></span></p>
</div>
<p>While we can see the bias is always a little worse in Ridge Regression, the variance takes a sharper decline; eventually we end up with a better out-of-sample MSE than we did with OLS.</p>
</section>
</section>
<section id="bias-and-variance-under-non-linear-dgp" class="level1">
<h1>5. Bias and Variance under non-Linear DGP</h1>
<section id="monte-carlo-simulation-for-non-linear-dgp" class="level2">
<h2 class="anchored" data-anchor-id="monte-carlo-simulation-for-non-linear-dgp">5.1 Monte Carlo Simulation for non-Linear DGP</h2>
<p>Similar to the previous section, here we will look at how bias and variance are affected when the DGP is non-linear, <span class="math inline">\(y=X^2 \beta + \epsilon\)</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>lambda_ridge <span class="ot">&lt;-</span> <span class="fl">1.0</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">2</span>)  <span class="co"># Intercept and quadratic coefficient</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to simulate non-linear DGP: y = β0 + β1 * x^2 + ε</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>generate_nonlinear_dgp <span class="ot">&lt;-</span> <span class="cf">function</span>(n, <span class="at">beta =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">2</span>), <span class="at">noise_sd =</span> <span class="fl">1.0</span>) {</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> beta[<span class="dv">1</span>] <span class="sc">+</span> beta[<span class="dv">2</span>] <span class="sc">*</span> x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> noise_sd)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">x =</span> x, <span class="at">y =</span> y))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Storage for results</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>ridge_nonlinear_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  beta_estimates <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> num_simulations, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  in_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  out_sample_mse <span class="ot">&lt;-</span> <span class="fu">numeric</span>(num_simulations)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (sim <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_simulations) {</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate training data</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">&lt;-</span> <span class="fu">generate_nonlinear_dgp</span>(n)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> train<span class="sc">$</span>x</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> train<span class="sc">$</span>y</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    X_quad <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit Ridge regression</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    ridge_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x =</span> X_quad, <span class="at">y =</span> y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> lambda_ridge,</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>                          <span class="at">intercept =</span> <span class="cn">FALSE</span>, <span class="at">standardize =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    beta_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(<span class="fu">coef</span>(ridge_model, <span class="at">s =</span> lambda_ridge))[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    beta_estimates[sim, ] <span class="ot">&lt;-</span> beta_hat</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># In-sample MSE</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="ot">&lt;-</span> X_quad <span class="sc">%*%</span> beta_hat</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    in_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Test set</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">&lt;-</span> <span class="fu">generate_nonlinear_dgp</span>(n)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    x_test <span class="ot">&lt;-</span> test<span class="sc">$</span>x</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    y_test <span class="ot">&lt;-</span> test<span class="sc">$</span>y</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    X_test_quad <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, x_test<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="ot">&lt;-</span> X_test_quad <span class="sc">%*%</span> beta_hat</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    out_sample_mse[sim] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y_test <span class="sc">-</span> y_test_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Bias and variance for β1 (quadratic term)</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>  beta1_hat <span class="ot">&lt;-</span> beta_estimates[, <span class="dv">2</span>]</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>  bias_beta1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(beta1_hat) <span class="sc">-</span> beta[<span class="dv">2</span>]</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>  variance_beta1 <span class="ot">&lt;-</span> <span class="fu">var</span>(beta1_hat)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store results</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>  ridge_nonlinear_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ridge_nonlinear_results, <span class="fu">data.frame</span>(</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> n,</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_beta1 =</span> bias_beta1,</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    <span class="at">variance_beta1 =</span> variance_beta1,</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>    <span class="at">in_sample_mse =</span> <span class="fu">mean</span>(in_sample_mse),</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">out_sample_mse =</span> <span class="fu">mean</span>(out_sample_mse)</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Bias</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_nonlinear_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> bias_beta1)) <span class="sc">+</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkred"</span>) <span class="sc">+</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bias of β1 vs. Sample Size (Ridge - Non-Linear)"</span>,</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Bias"</span>)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Variance</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_nonlinear_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> variance_beta1)) <span class="sc">+</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>) <span class="sc">+</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Variance of β1 vs. Sample Size (Ridge - Non-Linear)"</span>,</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"Variance"</span>)</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a><span class="co"># In-sample MSE</span></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_nonlinear_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> in_sample_mse)) <span class="sc">+</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"In-Sample MSE vs. Sample Size (Ridge - Non-Linear)"</span>,</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Out-of-sample MSE</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ridge_nonlinear_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> out_sample_mse)) <span class="sc">+</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkmagenta"</span>) <span class="sc">+</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Out-of-Sample MSE vs. Sample Size (Ridge - Non-Linear)"</span>,</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>, <span class="at">y =</span> <span class="st">"MSE"</span>)</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Display 2x2 grid</span></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Research_Report_1_files/figure-html/linear-dgp-monte-carlo-bias-variance_[12]-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="center-image" style="text-align: center;">
<p><span style="color:gray; font-size:90%"> <em>Bias and Variance of non-Linear DGP using Monte Carlo simulations</em></span></p>
</div>
<p>The bias is now nearly constant as seen in the top-left, while the in-and-out of sample errors seem to still follow the trends we saw with the last two.</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Mean_squared_error">MSE Wikipedia</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">Gauss-Markov Theorem Wikipedia</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://rdrr.io/cran/ISLR/man/Credit.html">ISL Credit Card Data</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://en.wikipedia.org/wiki/Gradient">Gradient Wikipedia</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/SethKauf\.github\.io\/Portfolio\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>